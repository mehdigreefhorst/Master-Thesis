{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d08bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.responses import ParsedResponse\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f129f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '\\nYou are an expert market researcher specializing in Reddit discourse analysis. Your task is to generate 5-8 strategically chosen keywords that will uncover the most relevant discussions about a specific project idea on Reddit.\\n\\nThese keywords should act as precision search terms to find posts and comments where people are genuinely discussing, experiencing, or seeking solutions related to the project\\'s domain.\\n\\n<instructions>\\nGenerate between 5-8 keywords (NEVER MORE THAN 8) that capture multiple dimensions of the project space. Each keyword must be smartly selected and strategically chosen:\\n\\n**Core Product/Service Keywords:**\\n- Direct terms for the main technology, product, or service\\n- Industry-specific terminology and jargon\\n- Technical specifications and features that matter to users\\n\\n**Problem-Focused Keywords:**\\n- Pain points and frustrations users explicitly mention\\n- Common complaints and recurring issues\\n- \"I wish there was...\" or \"Why doesn\\'t...\" type expressions\\n- Error messages, bugs, or failure scenarios people discuss\\n\\n**Solution-Seeking Keywords:**\\n- Terms people use when asking for recommendations\\n- Comparison language (\"X vs Y\", \"better than\", \"alternative to\")\\n- Words indicating research behavior (\"looking for\", \"anyone tried\", \"reviews\")\\n\\n**Competitor and Market Keywords:**\\n- Existing tools, platforms, or solutions in the space\\n- Brand names and product names users mention\\n- Category names and market segments\\n\\n**User Journey Keywords:**\\n- Terms related to getting started, learning, or adoption challenges\\n- Advanced use cases and power user discussions\\n- Integration, setup, and configuration topics\\n\\n**Emotional and Contextual Keywords:**\\n- Expressions of frustration, excitement, or urgency\\n- Situational contexts where the problem occurs\\n- Workflow disruptions or efficiency concerns\\n\\n**Language Variations:**\\n- Include both technical and casual terminology\\n- Consider abbreviations, acronyms, and slang\\n- Account for different expertise levels (beginner vs expert language)\\n- Include typos or common misspellings of technical terms\\n\\nCRITICAL: You must NEVER generate more than 8 keywords. If fewer high-quality keywords exist, provide only those (minimum 5, maximum 8).\\n\\nAll keywords must be smartly selected - avoid generic buzzwords, overly broad terms that would return irrelevant results, or keywords that stray from the core project focus. Each keyword should have a clear connection to either the problem the project solves or the solution it provides.\\n\\nBalance specificity with discoverability - keywords should be narrow enough to find relevant content but broad enough to capture the full conversation landscape.\\n</instructions>\\n\\n<response_format>\\nReturn your response as a JSON object following this exact format:\\n{\\'properties\\': {\\'keywords\\': {\\'description\\': \\'List of keywords\\', \\'items\\': {\\'type\\': \\'string\\'}, \\'title\\': \\'Keywords\\', \\'type\\': \\'array\\'}}, \\'required\\': [\\'keywords\\'], \\'title\\': \\'RedditKeywords\\', \\'type\\': \\'object\\'}\\n</response_format> \\n\\nProject Idea: \\nWe want to improve the experience for deaf people during the watching of videos. Deaf people do not hear so they are dependent on visuals of the video and subtitles. The group that is hard of hearing might be fine but I am not sure. I want to figure out what is needed to improve their video experience\\n\\n'\n",
    "llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "model_name ='gpt-5-nano-2025-08-07'\n",
    "messages = [{'role': 'user', 'content': '\\nYou are an expert market researcher specializing in Reddit discourse analysis. Your task is to generate 5-8 strategically chosen keywords that will uncover the most relevant discussions about a specific project idea on Reddit.\\n\\nThese keywords should act as precision search terms to find posts and comments where people are genuinely discussing, experiencing, or seeking solutions related to the project\\'s domain.\\n\\n<instructions>\\nGenerate between 5-8 keywords (NEVER MORE THAN 8) that capture multiple dimensions of the project space. Each keyword must be smartly selected and strategically chosen:\\n\\n**Core Product/Service Keywords:**\\n- Direct terms for the main technology, product, or service\\n- Industry-specific terminology and jargon\\n- Technical specifications and features that matter to users\\n\\n**Problem-Focused Keywords:**\\n- Pain points and frustrations users explicitly mention\\n- Common complaints and recurring issues\\n- \"I wish there was...\" or \"Why doesn\\'t...\" type expressions\\n- Error messages, bugs, or failure scenarios people discuss\\n\\n**Solution-Seeking Keywords:**\\n- Terms people use when asking for recommendations\\n- Comparison language (\"X vs Y\", \"better than\", \"alternative to\")\\n- Words indicating research behavior (\"looking for\", \"anyone tried\", \"reviews\")\\n\\n**Competitor and Market Keywords:**\\n- Existing tools, platforms, or solutions in the space\\n- Brand names and product names users mention\\n- Category names and market segments\\n\\n**User Journey Keywords:**\\n- Terms related to getting started, learning, or adoption challenges\\n- Advanced use cases and power user discussions\\n- Integration, setup, and configuration topics\\n\\n**Emotional and Contextual Keywords:**\\n- Expressions of frustration, excitement, or urgency\\n- Situational contexts where the problem occurs\\n- Workflow disruptions or efficiency concerns\\n\\n**Language Variations:**\\n- Include both technical and casual terminology\\n- Consider abbreviations, acronyms, and slang\\n- Account for different expertise levels (beginner vs expert language)\\n- Include typos or common misspellings of technical terms\\n\\nCRITICAL: You must NEVER generate more than 8 keywords. If fewer high-quality keywords exist, provide only those (minimum 5, maximum 8).\\n\\nAll keywords must be smartly selected - avoid generic buzzwords, overly broad terms that would return irrelevant results, or keywords that stray from the core project focus. Each keyword should have a clear connection to either the problem the project solves or the solution it provides.\\n\\nBalance specificity with discoverability - keywords should be narrow enough to find relevant content but broad enough to capture the full conversation landscape.\\n</instructions>\\n\\n<response_format>\\nReturn your response as a JSON object following this exact format:\\n{\\'properties\\': {\\'keywords\\': {\\'description\\': \\'List of keywords\\', \\'items\\': {\\'type\\': \\'string\\'}, \\'title\\': \\'Keywords\\', \\'type\\': \\'array\\'}}, \\'required\\': [\\'keywords\\'], \\'title\\': \\'RedditKeywords\\', \\'type\\': \\'object\\'}\\n</response_format> \\n\\nProject Idea: \\nWe want to improve the experience for deaf people during the watching of videos. Deaf people do not hear so they are dependent on visuals of the video and subtitles. The group that is hard of hearing might be fine but I am not sure. I want to figure out what is needed to improve their video experience\\n\\n'} ]\n",
    "response = llm.chat.completions.create(\n",
    "            model=model_name, \n",
    "            messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b30af9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprompt\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0754f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object', 'keywords': ['captions accuracy', 'captions sync timing', 'SDH subtitles', 'ASL overlay', 'how to enable captions', 'YouTube captions quality', 'caption customization font size contrast']}\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c4d9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'keywords': {'description': 'List of keywords',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Keywords',\n",
       "   'type': 'array'}},\n",
       " 'required': ['keywords'],\n",
       " 'title': 'RedditKeywords',\n",
       " 'type': 'object',\n",
       " 'keywords': ['captions accuracy',\n",
       "  'captions sync timing',\n",
       "  'SDH subtitles',\n",
       "  'ASL overlay',\n",
       "  'how to enable captions',\n",
       "  'YouTube captions quality',\n",
       "  'caption customization font size contrast']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_dict = {'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object', 'keywords': ['captions accuracy', 'captions sync timing', 'SDH subtitles', 'ASL overlay', 'how to enable captions', 'YouTube captions quality', 'caption customization font size contrast']}\n",
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6baaf72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finish_reason': 'stop',\n",
       " 'index': 0,\n",
       " 'message': {'content': \"{'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object', 'keywords': ['captions accuracy', 'captions sync timing', 'SDH subtitles', 'ASL overlay', 'how to enable captions', 'YouTube captions quality', 'caption customization font size contrast']}\",\n",
       "  'refusal': None,\n",
       "  'role': 'assistant',\n",
       "  'annotations': []}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c64fcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-COhSOaSgPtbGbzLJKjFD6OfCxAkW3',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': \"{'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object', 'keywords': ['captions accuracy', 'captions sync timing', 'SDH subtitles', 'ASL overlay', 'how to enable captions', 'YouTube captions quality', 'caption customization font size contrast']}\",\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'annotations': []}}],\n",
       " 'created': 1760002956,\n",
       " 'model': 'gpt-5-nano-2025-08-07',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'completion_tokens': 2028,\n",
       "  'prompt_tokens': 665,\n",
       "  'total_tokens': 2693,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 1920,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ef4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-COhpZIHiSmQj8LokQDgqgzLbZbcf9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"{'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object'}\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760004393, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=65, prompt_tokens=665, total_tokens=730, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1 = llm.chat.completions.create(\n",
    "            model=model_name, \n",
    "            messages=messages,\n",
    "            reasoning_effort=\"minimal\")\n",
    "response_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "163cfbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object'}\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ad866ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'keywords': {'description': 'List of keywords',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Keywords',\n",
       "   'type': 'array'}},\n",
       " 'required': ['keywords'],\n",
       " 'title': 'RedditKeywords',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resonse_1_text = {'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object'}\n",
    "resonse_1_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2123819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-COhrOHW8qPVa13ZivUHGNUnwzvpZT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"{'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object', 'keywords': ['open captions vs closed captions', 'subtitles for the deaf and hard of hearing (SDH)', 'auto captions accuracy YouTube Netflix', 'caption timing out of sync complaint', 'visual sound cues (doorbell siren laughter) in captions', 'ASL overlay picture-in-picture video', 'recommendations captioning tools apps', 'accessibility settings video players (HDR contrast font)'] }\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760004506, model='gpt-5-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=149, prompt_tokens=665, total_tokens=814, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2 = llm.chat.completions.create(\n",
    "            model=\"gpt-5\", \n",
    "            messages=messages,\n",
    "            reasoning_effort=\"minimal\")\n",
    "response_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ef3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object', 'keywords': ['open captions vs closed captions', 'subtitles for the deaf and hard of hearing (SDH)', 'auto captions accuracy YouTube Netflix', 'caption timing out of sync complaint', 'visual sound cues (doorbell siren laughter) in captions', 'ASL overlay picture-in-picture video', 'recommendations captioning tools apps', 'accessibility settings video players (HDR contrast font)'] }\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc474059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'keywords': {'description': 'List of keywords',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Keywords',\n",
       "   'type': 'array'}},\n",
       " 'required': ['keywords'],\n",
       " 'title': 'RedditKeywords',\n",
       " 'type': 'object',\n",
       " 'keywords': ['open captions vs closed captions',\n",
       "  'subtitles for the deaf and hard of hearing (SDH)',\n",
       "  'auto captions accuracy YouTube Netflix',\n",
       "  'caption timing out of sync complaint',\n",
       "  'visual sound cues (doorbell siren laughter) in captions',\n",
       "  'ASL overlay picture-in-picture video',\n",
       "  'recommendations captioning tools apps',\n",
       "  'accessibility settings video players (HDR contrast font)']}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2_dict ={'properties': {'keywords': {'description': 'List of keywords', 'items': {'type': 'string'}, 'title': 'Keywords', 'type': 'array'}}, 'required': ['keywords'], 'title': 'RedditKeywords', 'type': 'object', 'keywords': ['open captions vs closed captions', 'subtitles for the deaf and hard of hearing (SDH)', 'auto captions accuracy YouTube Netflix', 'caption timing out of sync complaint', 'visual sound cues (doorbell siren laughter) in captions', 'ASL overlay picture-in-picture video', 'recommendations captioning tools apps', 'accessibility settings video players (HDR contrast font)'] }\n",
    "response_2_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8aa5548f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-COhsuKhABXnsS8HFN0VIkPuv3jxRg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"properties\": {\\n    \"keywords\": {\\n      \"description\": \"List of keywords\",\\n      \"items\": {\\n        \"type\": \"string\"\\n      },\\n      \"title\": \"Keywords\",\\n      \"type\": \"array\"\\n    }\\n  },\\n  \"required\": [\\n    \"keywords\"\\n  ],\\n  \"title\": \"RedditKeywords\",\\n  \"type\": \"object\",\\n  \"keywords\": [\\n    \"SDH subtitles\",\\n    \"YouTube auto captions\",\\n    \"Netflix subtitles out of sync\",\\n    \"subtitles too small\",\\n    \"dialogue boost\",\\n    \"Live Caption\",\\n    \"ASL interpreter overlay\",\\n    \"OpenAI Whisper subtitles\"\\n  ]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760004600, model='gpt-5-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=5013, prompt_tokens=665, total_tokens=5678, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=4864, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_3 = llm.chat.completions.create(\n",
    "            model=\"gpt-5\", \n",
    "            messages=messages,\n",
    "            reasoning_effort=\"high\")\n",
    "response_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13294046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'keywords': {'description': 'List of keywords',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Keywords',\n",
       "   'type': 'array'}},\n",
       " 'required': ['keywords'],\n",
       " 'title': 'RedditKeywords',\n",
       " 'type': 'object',\n",
       " 'keywords': ['SDH subtitles',\n",
       "  'YouTube auto captions',\n",
       "  'Netflix subtitles out of sync',\n",
       "  'subtitles too small',\n",
       "  'dialogue boost',\n",
       "  'Live Caption',\n",
       "  'ASL interpreter overlay',\n",
       "  'OpenAI Whisper subtitles']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response_3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ca90b",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "OpenAI is blowing up the tokens with the reasoning. The documentation also changed since last time I used OPENAI, and when the github was created that I found that does pain point research on reddit automatically. Let's try the responses api instead of the chatcompletions api now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365d4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class RedditKeywords(BaseModel): \n",
    "    keywords: List[str] = Field(description=\"List of keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20faa2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "response_responses_1 = llm.responses.parse(model=\"gpt-5\",\n",
    "                    input=messages,\n",
    "                    text_format=RedditKeywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcc7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RedditKeywords(keywords=['SDH subtitles', 'YouTube auto captions accuracy', 'subtitle desync streaming', 'no captions on videos', 'Netflix subtitle readability settings', 'open captions vs closed captions', 'HoH friendly video recommendations', 'ASL interpreter overlay'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_responses_1.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bb2e106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RedditKeywords(keywords=['closed captions', 'auto-generated captions', 'SDH subtitles', 'caption sync', 'caption accuracy', 'sign language interpreter', 'how to enable captions', 'download subtitles'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_responses_2 = llm.responses.parse(model=\"gpt-5-mini\",\n",
    "                    input=messages,\n",
    "                    text_format=RedditKeywords)\n",
    "response_responses_2.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91428551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RedditKeywords(keywords=['live captions', 'captions accuracy', 'subtitle readability', 'ASL overlay', 'video accessibility', 'scene-by-scene transcripts', 'lip-reading reliance', 'auto-generated vs human captions'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_responses_3 = llm.responses.parse(model=\"gpt-5-nano\",\n",
    "                    input=messages,\n",
    "                    text_format=RedditKeywords)\n",
    "response_responses_3.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260980a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_responses_3.usage.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c756fc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RedditKeywords(keywords=['captioning accuracy', 'inaccessible videos', 'auto-generated subtitles issues', 'hard of hearing recommendations', 'sign language integration', 'subtitle customization', 'deaf video experience', 'missing audio cues'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_responses_4 = llm.responses.parse(model=\"gpt-4.1\",\n",
    "                    input=messages,\n",
    "                    text_format=RedditKeywords)\n",
    "response_responses_4.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "685be0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_responses_4.usage.output_tokens_details.reasoning_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ebda7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{1}.json\" == \"1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74acdbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['search_result.json',\n",
       " 'cached_comments1.json',\n",
       " 'post_entity.json',\n",
       " 'cached_post1.json',\n",
       " 'comments_result.json',\n",
       " 'search_result1.json']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a967f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RedditKeywords(keywords=['closed captions accuracy', 'auto-generated subtitles errors', 'best captioning tool for deaf', 'YouTube caption sync issue', 'VTT vs SRT for accessibility', 'how to add captions to personal videos', 'deaf-friendly video platforms', 'caption lag frustration'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_responses_5 = llm.responses.parse(model=\"gpt-oss-120b\",\n",
    "                    input=messages,\n",
    "                    text_format=RedditKeywords)\n",
    "response_responses_5.output_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "208290e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keywords': ['closed captions accuracy',\n",
       "  'auto-generated subtitles errors',\n",
       "  'best captioning tool for deaf',\n",
       "  'YouTube caption sync issue',\n",
       "  'VTT vs SRT for accessibility',\n",
       "  'how to add captions to personal videos',\n",
       "  'deaf-friendly video platforms',\n",
       "  'caption lag frustration']}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_responses_5.output_parsed.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d999bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseUsage(input_tokens=665, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=416, output_tokens_details=OutputTokensDetails(reasoning_tokens=256), total_tokens=1081)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_responses_5.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc85184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
